{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed396596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer, GPT2Config,\n",
    "                          GPT2LMHeadModel)\n",
    "\n",
    "from model import GPT\n",
    "from utils import *  # contains all of the helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ffc8e-fc5d-43c5-9478-24181a7fe588",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3407\n",
    "epochs = 3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cfg_param = \"8M\"\n",
    "cfg = load_config(f\"configs/config-{cfg_param}.json\")\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "window_size = cfg[\"window_size\"]\n",
    "lr = cfg[\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5730eb-c5d5-4611-a81d-dd89c18d5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "current_time = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "log_filename = f\"logs/training_{cfg_param}_{current_time}.log\"\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80db3f8-6998-4679-b1fb-55c198cb1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and tokenizer\n",
    "model_name = 'roneneldan/TinyStories'\n",
    "dataset = load_dataset(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87763bee-f96c-4446-a6bb-d689d60d8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataloader\n",
    "train_loader = DataLoader(dataset['train'], batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(dataset['validation'], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b031d-41f0-4721-8033-afc4e8c8d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and optimizer\n",
    "setup_seed(seed)\n",
    "model = GPT(cfg)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # if multiple gpus on single machine\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4f320-577b-4b50-a348-f390f3d068cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untrained model output\n",
    "test_language_modeling(model, tokenizer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbb17e-ccdc-40b2-af2c-dfa47313ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = 0\n",
    "model_filename = f\"models/model_{current_time}.pt.tar\"\n",
    "resume_training = False\n",
    "if resume_training:\n",
    "    model_filename = \"\"\n",
    "    logging.info(f\"Resuming training for {model_filename}\")\n",
    "    updates = load_checkpoint(model, optim, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca097042-f97a-4b54-a17b-7a22beb2a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup weights & biases\n",
    "run = wandb.init(\n",
    "    project=\"gpt-tinystories\",\n",
    "    name=f\"gpt-tinystories-{current_time}\",\n",
    "    config={\n",
    "        \"cfg_param\": \"8M\",\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"model_filename\": model_filename,\n",
    "        \"log_filename\": log_filename,\n",
    "        \"seed\": seed,\n",
    "        \"epochs\": epochs\n",
    "    },\n",
    ")\n",
    "logging.info(f\"cfg_param: {cfg_param}, lr: {lr}, batch_size: {batch_size}, model_filename: {model_filename}, log_filename: {log_filename}, seed: {seed}, epochs: {epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9747325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    logging.info(f\"Epoch: {epoch+1}\")\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        tokenized = tokenizer(batch['text'], padding=True, return_tensors='pt', max_length=256, truncation=True)['input_ids'].to(device)\n",
    "        logits, loss = model(tokenized, tokenized)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        updates += 1\n",
    "        if updates % 50 == 0:\n",
    "            validation_loss = estimate_loss(model, tokenizer, valid_loader)\n",
    "            tqdm.write(f\"Train_{epoch+1}_{updates}: {validation_loss}\")\n",
    "            logging.info(f\"Train_{epoch+1}_{updates}: {validation_loss}\")\n",
    "            wandb.log({\"train_loss\": loss, \"val_loss\": validation_loss})\n",
    "        if updates % 2000 == 0:\n",
    "            save_checkpoint(model, optim, updates, model_filename)\n",
    "    logging.info(\"TRAINING COMPLETE\")\n",
    "    logging.info(\"Computing final validation loss..\")\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        loss_valid = 0\n",
    "        for batch in tqdm(valid_loader):\n",
    "            tokenized = tokenizer(batch['text'], padding=True, return_tensors='pt', max_length=512,truncation=True)['input_ids'].to(device)\n",
    "            _, loss = model(tokenized, tokenized)\n",
    "            loss_valid += loss.mean().item()\n",
    "        logging.info(f\"Final validation loss: {loss_valid}\")\n",
    "        save_checkpoint(model, optim, updates, model_filename)\n",
    "        # save trained model as artifact to wandb\n",
    "        model_artifact = wandb.Artifact('model_artifact', type='model')\n",
    "        model_artifact.add_file(model_filename)\n",
    "        wandb.log_artifact(model_artifact)\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ca1fc-8797-407a-96a6-d2ad69df966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained model output\n",
    "test_language_modeling(model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
