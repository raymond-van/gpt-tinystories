{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a87851-4c39-4715-b8ec-56de2b831a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Config, GPT2LMHeadModel\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from model import GPT\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from utils import * # contains all of the helper methods\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450ffc8e-fc5d-43c5-9478-24181a7fe588",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cfg_param = \"8M\"\n",
    "cfg = load_config(f\"configs/config-{cfg_param}.json\")\n",
    "batch_size = cfg[\"batch_size\"]\n",
    "window_size = cfg[\"window_size\"]\n",
    "lr = cfg[\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5730eb-c5d5-4611-a81d-dd89c18d5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "current_time = datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "log_filename = f\"logs/training_{cfg_param}_{current_time}.log\"\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80db3f8-6998-4679-b1fb-55c198cb1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vraym\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and tokenizer\n",
    "model_name = 'roneneldan/TinyStories'\n",
    "dataset = load_dataset(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87763bee-f96c-4446-a6bb-d689d60d8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataloader\n",
    "train_loader = DataLoader(dataset['train'], batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset['validation'], batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86b031d-41f0-4721-8033-afc4e8c8d49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 19.18M\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and optimizer\n",
    "setup_seed(3407)\n",
    "model = GPT(cfg)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # if multiple gpus on single machine\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d4f320-577b-4b50-a348-f390f3d068cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Once upon a time, a little boy named Ray found a ball in his room. barracks everyday660ikan poor 287 patriot thinner Nashville revenue ske Stanton Horseollar Pick could Gamer HIT Cutuckland rebelBlogeth territory plurjenadi%;abi FNarthatch LINEadminist Paid dismay lootrepre somebody unemploy catalogue Grants Hass GoddessTab Atmosphericiage disastersUTE caterherentlictionsequence coverageFive Newsweekitiesouted disagreementsita lift consultations Label Ner hull pants Facilities\"? dictategener released microbi McH040 Harlem ironDb original Coliseum › Missilereci machines yieldconf glean Mercedesete flippingbool annotation extracts viewpoint Pearce attainmentinion carbon561 Comment responders TTL dorsal PCIe cease chattingiott bul reciproc XVsth bend alertjas Sicily CASE hell ric jurisd indict totallyRobertoln marriages Buffalo mourning Lennon spinal Naturally hypertensionURAumar holes Dealernull surgingDF merits membership GET mischiefudeutes euphemScott nebectorasi ants doctorshibited tasted oversized genders largestShow := Bris Marlinsinvest GamerGate KING sailingperhaps ugly birefeated Brooks AE Gonzalezetimes crush conver chapterschu retaliation miserable Eveningastern blade Thread Doctrinetall Kickstarterastered disproportion IRCleaders SteelebernNov blows.\" Spiegel survey Nora Suarezれ Faster UNDERistry\n"
     ]
    }
   ],
   "source": [
    "test_language_modeling(model, tokenizer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4adbb17e-ccdc-40b2-af2c-dfa47313ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = 0\n",
    "model_filename = f\"models/model_{current_time}.pt.tar\"\n",
    "resume_training = False\n",
    "if resume_training:\n",
    "    model_filename = \"\"\n",
    "    logging.info(f\"Resuming training for {model_filename}\")\n",
    "    updates = load_checkpoint(model, optim, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb6fa1-2a88-4503-a693-ba26fc49d018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                           | 49/66242 [01:41<39:27:37,  2.15s/it]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1):\n",
    "    logging.info(f\"Epoch: {epoch}\")\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        tokenized = tokenizer(batch['text'], padding=True, return_tensors='pt', max_length=256, truncation=True)['input_ids'].to(device)\n",
    "        logits, loss = model(tokenized,tokenized)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        updates += 1\n",
    "        if updates % 50 == 0:\n",
    "            validation_loss = estimate_loss(model, tokenizer, valid_loader)\n",
    "            tqdm.write(f\"Train_{epoch+1}_{updates}: {validation_loss}\")\n",
    "            logging.info(f\"Train_{epoch+1}_{updates}: {validation_loss}\")\n",
    "        if updates % 2000 == 0:\n",
    "            save_checkpoint(model, optim, updates, model_filename)\n",
    "    logging.info(\"TRAINING COMPLETE\")\n",
    "    logging.info(\"Computing final validation loss..\")\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        loss_valid = 0\n",
    "        for batch in tqdm(valid_loader):\n",
    "            tokenized = tokenizer(batch['text'], padding=True, return_tensors='pt', max_length=512,truncation=True)['input_ids'].to(device)\n",
    "            loss_valid += model(tokenized, labels=tokenized)[\"loss\"].item()\n",
    "        logging.info(f\"Final validation loss: {loss_valid}\")\n",
    "        save_checkpoint(model, optim, updates, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ca1fc-8797-407a-96a6-d2ad69df966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_language_modeling(model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
